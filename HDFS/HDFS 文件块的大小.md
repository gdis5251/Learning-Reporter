# HDFS 文件块的大小

HDFS 中的文件在物理磁盘上是通过分块存储的，块的大小可以通过参数配置（dfs.blocksize）来决定，在 Hadoop >= 2.x 版本中是 128M，老版本是 64M

## 举个栗子

1. 假如磁盘的寻址时间约为 10ms，即查找到目标 Block 的时间为 10ms
2. 根据规定，寻址时间为传输时间的 1%时，为最佳状态。因此传输时间= 10ms / 0.1 = 1s
3. 若磁盘的传输速率为 100M/s
4. 那么块的大小最佳为 100M。

以上例子都取的大概值，根据测算，机械硬盘中块的大小最佳为 128M

## 思考

为什么块的大小不能设置的太大？或者太小？

1. 如果块的大小设置过于大，寻址时间很快，但是数据传输的时间过于慢，导致程序阻塞等待数据传输，造成性能卡点。
2. 如果块的大小设置的太小，那么会极大的增加寻址时间。eg：比如块太小，有 100W 个文件，这时寻址需要遍历这 100W 个文件找到对应的文件，就浪费很多时间。